
import numpy as np
import os
import torch

from inspect import getsourcefile
import os.path
import sys
import SimpleITK as sitk
os.environ["CUDA_VISIBLE_DEVICES"] ="0"

current_path = os.path.abspath(getsourcefile(lambda:0))
current_dir = os.path.dirname(current_path)
parent_dir = current_dir[:current_dir.rfind(os.path.sep)]

sys.path.insert(0, parent_dir)

from test_lymph.lungmask_model import LungMaskExtractionModel
from test_lymph.utils import load_itk_image_with_sampling, crop_image_via_box, restore_image_via_box, \
    InnerTransformer, mkdir

from test_lymph.airway_model import AirwayExtractionModel

from test_lymph.utils import save_itk_with_backsampling_with_ConnectedComponent

import argparse
from nnunet.inference.predict import predict_from_folder
from nnunet.paths import default_plans_identifier, network_training_output_dir, default_cascade_trainer, default_trainer
from batchgenerators.utilities.file_and_folder_operations import join, isdir
from nnunet.utilities.task_name_id_conversion import convert_id_to_task_name
import shutil
from natsort import natsorted
import time
import json

parser = argparse.ArgumentParser()
parser.add_argument("-i", '--input',
                    help="Must contain all modalities for each patient in the correct"
                         " order (same as training). Files must be named "
                         "CASENAME_XXXX.nii.gz where XXXX is the modality "
                         "identifier (0000, 0001, etc)",
                    required=False,
                    default= "D:/LNQ/3_Code_nnUnet_inference/lnq_model_github/dataset/")

# parser.add_argument("-i", '--input',
#                     help="Must contain all modalities for each patient in the correct"
#                          " order (same as training). Files must be named "
#                          "CASENAME_XXXX.nii.gz where XXXX is the modality "
#                          "identifier (0000, 0001, etc)",
#                     required=True)

parser.add_argument('-o', "--output",
                    required=False,
                    default="D:/LNQ/3_Code_nnUnet_inference/lnq_model_github/dataset_infer/",
                    help="folder for saving predictions")

# parser.add_argument('-o', "--output",
#                     required=True,
#                     help="folder for saving predictions")

parser.add_argument('-t', '--task_name', help='task name or task ID, required.',
                    # default=default_plans_identifier,
                    default='007',
                    required=False)

parser.add_argument('-tr', '--trainer_class_name',
                    help='Name of the nnUNetTrainer used for 2D U-Net, full resolution 3D U-Net and low resolution '
                         'U-Net. The default is %s. If you are running inference with the cascade and the folder '
                         'pointed to by --lowres_segmentations does not contain the segmentation maps generated by '
                         'the low resolution U-Net then the low resolution segmentation maps will be automatically '
                         'generated. For this case, make sure to set the trainer class here that matches your '
                         '--cascade_trainer_class_name (this part can be ignored if defaults are used).'
                         % default_trainer,
                    required=False,
                    default=default_trainer)
parser.add_argument('-ctr', '--cascade_trainer_class_name',
                    help="Trainer class name used for predicting the 3D full resolution U-Net part of the cascade."
                         "Default is %s" % default_cascade_trainer, required=False,
                    default=default_cascade_trainer)

parser.add_argument('-m', '--model', help="2d, 3d_lowres, 3d_fullres or 3d_cascade_fullres. Default: 3d_fullres",
                    default="3d_fullres", required=False)

parser.add_argument('-p', '--plans_identifier', help='do not touch this unless you know what you are doing',
                    default=default_plans_identifier, required=False)

parser.add_argument('-f', '--folds', nargs='+', default='None',
                    help="folds to use for prediction. Default is None which means that folds will be detected "
                         "automatically in the model output folder")

parser.add_argument('-z', '--save_npz', required=False, action='store_true',
                    help="use this if you want to ensemble these predictions with those of other models. Softmax "
                         "probabilities will be saved as compressed numpy arrays in output_folder and can be "
                         "merged between output_folders with nnUNet_ensemble_predictions")

parser.add_argument('-l', '--lowres_segmentations', required=False, default='None',
                    help="if model is the highres stage of the cascade then you can use this folder to provide "
                         "predictions from the low resolution 3D U-Net. If this is left at default, the "
                         "predictions will be generated automatically (provided that the 3D low resolution U-Net "
                         "network weights are present")

parser.add_argument("--part_id", type=int, required=False, default=0, help="Used to parallelize the prediction of "
                                                                           "the folder over several GPUs. If you "
                                                                           "want to use n GPUs to predict this "
                                                                           "folder you need to run this command "
                                                                           "n times with --part_id=0, ... n-1 and "
                                                                           "--num_parts=n (each with a different "
                                                                           "GPU (for example via "
                                                                           "CUDA_VISIBLE_DEVICES=X)")

parser.add_argument("--num_parts", type=int, required=False, default=1,
                    help="Used to parallelize the prediction of "
                         "the folder over several GPUs. If you "
                         "want to use n GPUs to predict this "
                         "folder you need to run this command "
                         "n times with --part_id=0, ... n-1 and "
                         "--num_parts=n (each with a different "
                         "GPU (via "
                         "CUDA_VISIBLE_DEVICES=X)")

parser.add_argument("--num_threads_preprocessing", required=False, default=6, type=int, help=
"Determines many background processes will be used for data preprocessing. Reduce this if you "
"run into out of memory (RAM) problems. Default: 6")

parser.add_argument("--num_threads_nifti_save", required=False, default=2, type=int, help=
"Determines many background processes will be used for segmentation export. Reduce this if you "
"run into out of memory (RAM) problems. Default: 2")

parser.add_argument("--disable_tta", required=False, default=False, action="store_true",
                    help="set this flag to disable test time data augmentation via mirroring. Speeds up inference "
                         "by roughly factor 4 (2D) or 8 (3D)")

parser.add_argument("--overwrite_existing", required=False, default=False, action="store_true",
                    help="Set this flag if the target folder contains predictions that you would like to overwrite")

parser.add_argument("--mode", type=str, default="normal", required=False, help="Hands off!")
parser.add_argument("--all_in_gpu", type=str, default="None", required=False, help="can be None, False or True. "
                                                                                   "Do not touch.")
parser.add_argument("--step_size", type=float, default=0.5, required=False, help="don't touch")
# parser.add_argument("--interp_order", required=False, default=3, type=int,
#                     help="order of interpolation for segmentations, has no effect if mode=fastest. Do not touch this.")
# parser.add_argument("--interp_order_z", required=False, default=0, type=int,
#                     help="order of interpolation along z is z is done differently. Do not touch this.")
# parser.add_argument("--force_separate_z", required=False, default="None", type=str,
#                     help="force_separate_z resampling. Can be None, True or False, has no effect if mode=fastest. "
#                          "Do not touch this.")
parser.add_argument('-chk',
                    help='checkpoint name, default: model_final_checkpoint',
                    required=False,
                    default='model_final_checkpoint')
parser.add_argument('--disable_mixed_precision', default=False, action='store_true', required=False,
                    help='Predictions are done with mixed precision by default. This improves speed and reduces '
                         'the required vram. If you want to disable mixed precision you can set this flag. Note '
                         'that yhis is not recommended (mixed precision is ~2x faster!)')

args = parser.parse_args()


def GetLargestConnectedCompont(binarysitk_image):
    cc = sitk.ConnectedComponent(binarysitk_image)
    stats = sitk.LabelIntensityStatisticsImageFilter()
    stats.SetGlobalDefaultNumberOfThreads(8)
    stats.Execute(cc, binarysitk_image)
    maxlabel = 0
    maxsize = 0
    for l in stats.GetLabels():
        size = stats.GetPhysicalSize(l)
        if maxsize < size:
            maxlabel = l
            maxsize = size
    labelmaskimage = sitk.GetArrayFromImage(cc)
    outmask = labelmaskimage.copy()
    outmask[labelmaskimage == maxlabel] = 1
    outmask[labelmaskimage != maxlabel] = 0
    outmask_sitk = sitk.GetImageFromArray(outmask)
    outmask_sitk.SetDirection(binarysitk_image.GetDirection())
    outmask_sitk.SetSpacing(binarysitk_image.GetSpacing())
    outmask_sitk.SetOrigin(binarysitk_image.GetOrigin())
    return outmask_sitk


def locate_airway_boundingbox(image):
    xx, yy, zz = np.where(image)
    airway_boundingbox = np.array([[np.min(xx), np.max(xx)], [np.min(yy), np.max(yy)], [np.min(zz), np.max(zz)]])
    margin = 20
    airway_boundingbox = np.vstack([np.max([[0, 0, 0], airway_boundingbox[:, 0] - margin], 0),
                                    np.min([np.array(image.shape), airway_boundingbox[:, 1] + margin], axis=0).T]).T
    return airway_boundingbox


def load_itk_image_new(filename):
    itkimage = sitk.ReadImage(filename)
    numpyImage = sitk.GetArrayFromImage(itkimage)
    numpyOrigin = list(reversed(itkimage.GetOrigin()))
    numpySpacing = list(reversed(itkimage.GetSpacing()))
    numpyDirection = list(reversed(itkimage.GetDirection()))
    return numpyImage, numpyOrigin, numpySpacing, numpyDirection


def save_itk_new(image, filename, origin, spacing, direction):
    if type(origin) != tuple:
        if type(origin) == list:
            origin = tuple(reversed(origin))
        else:
            origin = tuple(reversed(origin.tolist()))
    if type(spacing) != tuple:
        if type(spacing) == list:
            spacing = tuple(reversed(spacing))
        else:
            spacing = tuple(reversed(spacing.tolist()))
    if type(direction) != tuple:
        if type(direction) == list:
            direction = tuple(reversed(direction))
        else:
            direction = tuple(reversed(direction.tolist()))
    itkimage = sitk.GetImageFromArray(image, isVector=False)
    itkimage.SetSpacing(spacing)
    itkimage.SetOrigin(origin)
    itkimage.SetDirection(direction)
    sitk.WriteImage(itkimage, filename, True)


def lung_resample_and_crop_preprocess():
    img_dir = args.input
    img_list = natsorted(os.listdir(img_dir))
    lobeextractor = LungMaskExtractionModel()
    # this will re-write.
    file_lung_dic = {}
    for idx in range(len(img_list)):
        start_time = time.time()
        casename = img_list[idx]
        casename_nii = casename.replace('.nrrd', '.nii.gz')
        image_path = os.path.join(img_dir, img_list[idx])

        image_sitk, image_array, origin, spacing, new_spacing, direction, size = \
            load_itk_image_with_sampling(image_path, spacing=[0.8, 0.8, 0.8])

        lobe = lobeextractor.predict(image_sitk)

        print('The Lung Lobe Extraction Done!')
        lunglobe_boundingbox = lobeextractor.lung_boundingbox

        lunglobe_boundingbox[0, 1] = lunglobe_boundingbox[0, 1] + 20
        if lunglobe_boundingbox[0, 1] >= image_array.shape[0]:
            lunglobe_boundingbox[0, 1] = image_array.shape[0]

        image_crop = crop_image_via_box(image_array, lunglobe_boundingbox)

        airwayextractor = AirwayExtractionModel()
        airway2 = airwayextractor.predict(image_crop)

        airway2_post = InnerTransformer.KeepLargestConnectedComponent(airway2)  # Extract the largest domain
        airway2_post = InnerTransformer.ToNumpy(airway2_post)
        airway2_post = InnerTransformer.CastToNumpyUINT8(airway2_post[0, ...])
        torch.cuda.empty_cache()
        print('The Airway Extraction Done!')
        airway2_post = restore_image_via_box(image_array.shape, airway2_post, lunglobe_boundingbox)

        airway2_post_wo_lobe = airway2_post.copy()
        airway2_post_wo_lobe[lobe > 0] = 0

        airway_boundingbox = locate_airway_boundingbox(airway2_post_wo_lobe)

        new_boundingbox = airway_boundingbox.copy()

        new_boundingbox[0, 0] = new_boundingbox[0, 0] - 20
        if new_boundingbox[0, 0] < 0:
            new_boundingbox[0, 0] = 0
        new_boundingbox[0, 1] = lunglobe_boundingbox[0, 1]
        new_boundingbox[1, 0] = lunglobe_boundingbox[1, 0] + 20
        new_boundingbox[1, 1] = lunglobe_boundingbox[1, 1] - 20
        new_boundingbox[2, 0] = new_boundingbox[2, 0]
        new_boundingbox[2, 1] = new_boundingbox[2, 1]

        image_crop_new = crop_image_via_box(image_array, new_boundingbox)
        c_img = image_crop_new

        json_boundingbox = np.reshape(new_boundingbox, newshape=(6,))
        file_lung_dic[casename] = [int(json_boundingbox[0]), int(json_boundingbox[1]), int(json_boundingbox[2]),
                                   int(json_boundingbox[3]), int(json_boundingbox[4]), int(json_boundingbox[5])]

        affine = np.eye(4)
        affine[0, :3] = np.asarray(direction[:3]) * new_spacing[0]
        affine[1, :3] = np.asarray(direction[3:6]) * new_spacing[1]
        affine[2, :3] = np.asarray(direction[6:9]) * new_spacing[2]
        affine[0, 3] = origin[0]
        affine[1, 3] = origin[1]
        affine[2, 3] = origin[2]

        origin_point = [[new_boundingbox[0, 0], new_boundingbox[1, 0], new_boundingbox[2, 0], 1]]

        origin_P = np.transpose(origin_point)
        origin_nodule = np.dot(affine, origin_P)
        origin_N = np.transpose(origin_nodule[0:3, 0]).tolist()
        origin_new = origin_N

        print('case:{} lung crop taken {} s'.format(casename, time.time() - start_time))
        save_itk_new(c_img, os.path.join(LungCrop_out_dir, casename_nii), origin_new, tuple(new_spacing), direction)
        with open(lung_bbox_dict_path, 'w') as file:
            json.dump(file_lung_dic, file, indent=1)


def copy_and_rename_files_for_nnUNet_predict():
    origin_input_folder = LungCrop_out_dir
    if os.path.exists(nnUNet_in_dir):
        shutil.rmtree(nnUNet_in_dir)
    shutil.copytree(origin_input_folder, nnUNet_in_dir)

    filelist = natsorted(os.listdir(nnUNet_in_dir))
    for idx in range(0, len(filelist)):
        casename = filelist[idx].replace('.nii.gz', '_0000.nii.gz')
        os.rename(os.path.join(nnUNet_in_dir, filelist[idx]), os.path.join(nnUNet_in_dir, casename))


def nnUNet_predict():
    print('==== start nnUNet path ====')
    input_folder = nnUNet_in_dir
    output_folder = nnUNet_out_dir
    mkdir(output_folder)

    part_id = args.part_id
    num_parts = args.num_parts
    folds = args.folds
    save_npz = args.save_npz
    lowres_segmentations = args.lowres_segmentations
    num_threads_preprocessing = args.num_threads_preprocessing
    num_threads_nifti_save = args.num_threads_nifti_save
    disable_tta = args.disable_tta
    # print(disable_tta)
    step_size = args.step_size
    overwrite_existing = args.overwrite_existing
    mode = args.mode
    all_in_gpu = args.all_in_gpu
    model = args.model
    trainer_class_name = args.trainer_class_name
    cascade_trainer_class_name = args.cascade_trainer_class_name
    task_name = args.task_name

    if not task_name.startswith("Task"):
        task_id = int(task_name)
        task_name = convert_id_to_task_name(task_id)

    assert model in ["2d", "3d_lowres", "3d_fullres", "3d_cascade_fullres"], "-m must be 2d, 3d_lowres, 3d_fullres or " \
                                                                             "3d_cascade_fullres"

    if lowres_segmentations == "None":
        lowres_segmentations = None

    if isinstance(folds, list):
        if folds[0] == 'all' and len(folds) == 1:
            pass
        else:
            folds = [int(i) for i in folds]
    elif folds == "None":
        folds = None
    else:
        raise ValueError("Unexpected value for argument folds")

    assert all_in_gpu in ['None', 'False', 'True']
    if all_in_gpu == "None":
        all_in_gpu = None
    elif all_in_gpu == "True":
        all_in_gpu = True
    elif all_in_gpu == "False":
        all_in_gpu = False

    # we need to catch the case where model is 3d cascade fullres and the low resolution folder has not been set.
    # In that case we need to try and predict with 3d low res first
    if model == "3d_cascade_fullres" and lowres_segmentations is None:
        print("lowres_segmentations is None. Attempting to predict 3d_lowres first...")
        assert part_id == 0 and num_parts == 1, "if you don't specify a --lowres_segmentations folder for the " \
                                                "inference of the cascade, custom values for part_id and num_parts " \
                                                "are not supported. If you wish to have multiple parts, please " \
                                                "run the 3d_lowres inference first (separately)"
        model_folder_name = join(network_training_output_dir, "3d_lowres", task_name, trainer_class_name + "__" +
                                 args.plans_identifier)
        assert isdir(model_folder_name), "model output folder not found. Expected: %s" % model_folder_name
        lowres_output_folder = join(output_folder, "3d_lowres_predictions")
        predict_from_folder(model_folder_name, input_folder, lowres_output_folder, folds, False,
                            num_threads_preprocessing, num_threads_nifti_save, None, part_id, num_parts,
                            not disable_tta,
                            overwrite_existing=overwrite_existing, mode=mode, overwrite_all_in_gpu=all_in_gpu,
                            mixed_precision=not args.disable_mixed_precision,
                            step_size=step_size)
        lowres_segmentations = lowres_output_folder
        torch.cuda.empty_cache()
        print("3d_lowres done")

    if model == "3d_cascade_fullres":
        trainer = cascade_trainer_class_name
    else:
        trainer = trainer_class_name

    model_folder_name = join(network_training_output_dir, model, task_name, trainer + "__" +
                             args.plans_identifier)
    # print("using model stored in ", model_folder_name)
    assert isdir(model_folder_name), "model output folder not found. Expected: %s" % model_folder_name

    predict_from_folder(model_folder_name, input_folder, output_folder, folds, save_npz, num_threads_preprocessing,
                        num_threads_nifti_save, lowres_segmentations, part_id, num_parts, not disable_tta,
                        overwrite_existing=overwrite_existing, mode=mode, overwrite_all_in_gpu=all_in_gpu,
                        mixed_precision=not args.disable_mixed_precision,
                        step_size=step_size, checkpoint_name=args.chk)


def restore_image_via_box_from_json(origin_shape, image, lungbox):
    origin_image = np.zeros(shape=origin_shape, dtype=np.uint8)  # np.uint8 is default
    origin_image[lungbox[0]:lungbox[1], lungbox[2]:lungbox[3], lungbox[4]:lungbox[5]] = image
    return origin_image


def combine_nnUNet_and_UNet():
    if not os.path.exists(output_folder + 'woPost/'):
        os.makedirs(output_folder + 'woPost/')

    if not os.path.exists(output_folder + 'wPost/'):
        os.makedirs(output_folder + 'wPost/')

    pred_filelist_1 = natsorted(os.listdir(nnUNet_out_dir))
    original_image_filelist = natsorted(os.listdir(args.input))
    with open(lung_bbox_dict_path, 'r') as f:
        lung_bbox_val_dict = json.load(f)

    for file in pred_filelist_1:
        if file.endswith('nii.gz'):
            file_nrrd = file.replace('nii.gz', 'nrrd')
            image_sitk, image_array, origin, spacing, new_spacing, direction, size = \
                load_itk_image_with_sampling(os.path.join(args.input, file_nrrd), spacing=[0.8, 0.8, 0.8], islabel=True)
            pred_1, _, _, _ = load_itk_image_new(os.path.join(nnUNet_out_dir, file))
            file_seg_nrrd = file_nrrd.replace('-ct.nrrd', '-seg.nrrd')
            new_savedir = output_folder + 'woPost/'
            lymph_wopost_out_path = os.path.join(new_savedir, file_seg_nrrd)
            new_savedir_post = output_folder + 'wPost/'
            lymph_wpost_out_path = os.path.join(new_savedir_post, file_seg_nrrd)
            lungbox = lung_bbox_val_dict[file_nrrd]
            lymph_save = restore_image_via_box_from_json(image_array.shape, pred_1, lungbox)
            save_itk_with_backsampling_with_ConnectedComponent(lymph_save, lymph_wopost_out_path, lymph_wpost_out_path,
                                                               origin, new_spacing, spacing, direction, size, islabel=True)


'''
    Runs the application.
'''
if __name__ == '__main__':
    ## Global Temp Variables
    LungCrop_out_dir = './c_input'
    mkdir(LungCrop_out_dir)

    lung_bbox_dict_path = "./lung_bbox_dict.json"
    nnUNet_in_dir = './nnUNet_input'
    nnUNet_out_dir = './nnUNet_output'
    UNet_out_dir = './UNet_output'
    output_folder = args.output
    mkdir(output_folder)

    lung_resample_and_crop_preprocess()
    copy_and_rename_files_for_nnUNet_predict()
    nnUNet_predict()
    combine_nnUNet_and_UNet()








